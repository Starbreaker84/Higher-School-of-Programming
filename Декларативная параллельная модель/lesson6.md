### Базовые техники программирования с нитями

Принципы параллелизма в Julia мы изучали на первом курсе данного трека. Напомню, что dataflow-переменные в семантике
чистой декларативной модели Julia не поддерживает просто потому, что это не декларативный язык. Однако они легко
моделируются, хоть и дополнительным кодом, который надо писать вручную: это прежде всего макро @isdefined, или просто
проверка, изменилось ли значение некоторой переменной в сравнении с заданным по умолчанию. Главный недостаток такого
подхода -- необходимость явно кодировать соответствующую логику, что существенно понижает выразительность.

В Julia имеются две основные схемы организации одновременного выполнения. Одну мы изучили: это макро @threads в начале
цикла, которое задаёт одновременное выполнение всех "тел" цикла (конкретный их порядок неизвестен в принципе). Вторая
схема добавляет простое понятие "задачи": любая функция может быть выполнена в нити, что задаётся макро @spawn.

```
t = @spawn f(123)
```

t получает значение не результата вызова f(123), а некоторый внутренний идентификатор параллельной задачи. С такого
момента f(123) запускается в первой доступной нити на одновременное выполнение с последующим кодом основной программы.
Когда потребуется конкретный результат работы этой функции, делается вызов fetch(t), который приостанавливает выполнение
и ждёт завершения задачи t (если она ещё выполняется), после чего возвращает её результат. Например:

```
import Base.Threads.@spawn

t = @spawn 10*10
X = fetch(t) + 100*100
println(X)
```

Другой вариант ожидания завершения -- вызов wait(t), которая просто ожидает выполнения некоторой части кода.

```
import Base.Threads.@spawn

global Y # = 0
t = @spawn global Y = 10*10
wait(t)
X = Y + 100*100
println(X)
```

Наконец, моделируем декларативную параллельность "вручную":

```
import Base.Threads.@spawn

global Y = 0

t = @spawn global Y = 10*10

while Y == 0

end

X = Y + 100*100

println(X)
```

или более корректно (допускаются только однократные присваивания):

```
import Base.Threads.@spawn

global Y 

t = @spawn global Y = 10*10

while ! @isdefined(Y)

end

X = Y + 100*100

println(X)
```

Но подобный стиль, понятно, на практике неудобен, поэтому так важна поддержка dataflow-переменных непосредственно на
уровне языка программирования.

Отметим следующие формальные моменты.

Когда у нити больше нет операторов для выполнения, она завершается.

Каждая незавершённая нить, которая не приостановлена, в конечном итоге будет запущена (её выполнение гарантированно
продолжится).

Выполнение нитей планируется справедливо. Оно реализовано так называемым  **вытесняющим планированием** : если к
выполнению готова более чем одна нить, то каждая из них будет получать процессорное время в дискретных интервалах,
называемых **временными срезами** (time slices). Невозможно, чтобы одна нить захватила всё процессорное время.

Важно также всегда помнить, что  **каждая нить -- это dataflow-нить** , т.е. её выполнение или приостановление зависит
от наличия реальных данных (связывания значений с переменными).

Вспомним функцию Map (реализацию стандартной map из схемы map/reduce).

```
function Map(Ls, F)

  function IterMap(Rs, Ys, F)
    if Ys == []
        return Rs
    end

    head = Ys[1]
    tail = Ys[2:end]
    return IterMap(push!(Rs,F(head)), tail, F)
  end

  return IterMap([], Ls, F)
end

function Square(x)
    return x*x
end

println(Map([1,5,3,7,9], Square))
```

Полноценно записать на Julia (и на многих других языках) чистую декларативную версию этой функции к сожалению
невозможно. Простой вариант: перебрать в цикле (лучше нерекурсивно) все элементы в списке, для каждого элемента
запустить нить (через @spawn), в которой над ним вычисляется заданная функция, сохраняя соответствующую "задачу" в
промежуточном списке, и затем уже последовательно по каждой "задаче" ждём, когда она закончится (fetch), выдавая в
итоговый список результат её работы. Но этот подход подразумевает работу с состояниями, да и рекурсивных функций
потребуется две, для наглядности.

Например:

```
import Base.Threads.@spawn

function Map(Ls, F)

  Rs = []

  function IterMap(Ys, F)
    if Ys == []
        return
    end

    head = Ys[1]
    tail = Ys[2:end]
    t = @spawn F(head)
    IterMap(tail, F)

    pushfirst!(Rs,fetch(t))
  end

  IterMap(Ls, F)
  return Rs
end

function Square(x)
    return x*x
end

println(Map([1,5,3,7,9], Square))
```

Мы стараемся не прерывать рекурсию, пока происходит вычисление предыдущих вызовов F(), и формируем результат только
после того, как все нити с вычислением F запущены. Однако тут приходится использовать замыкание: "глобальное" состояние
Rs.

Идеальная декларативная параллельная версия будет очень похожа на первую исходную вышеприведённую. По сути, единственное
отличие в том, что вызов функции F мы просто оформляем синтаксически как параллельный -- в нити, всё остальное сделает
сама система. Рекурсивные вызовы будут в такой схеме продолжать разворачиваться, несмотря на то, что второй параметр F в
вызове push!(Rs,F(head)) будет какое-то (возможно, долгое) время оставаться невычисленным и пока несвязанным, однако
рекурсивный процесс выполнения функции IterMap будет продолжаться, пока все её экземпляры не окажутся приостановленными.
Как только вычисление некоторой F закончится, выполнение в соответствующей точке будет продолжено (такая схема немного
похожа на ленивое выполнение).
Rs заполняется несвязанными переменными, но программа продолжает работать. А код, запросивший значение какой-то
несвязаннной переменной из Rs, просто будет ожидать её связывания (когда отработает нить, рассчитывающая соответствующий
вызов F).

Итак, мы пришли к тому, что любую декларативную программу можно сделать параллельной, просто поместив в нить (указав это
с помощью простого синтаксиса) некоторые её операторы и выражения. Поскольку каждая dataflow-переменная будет связана с
одним и тем же значением, то и конечный результат параллельной версии будет точно таким же, как и исходной
последовательной версии.

К сожалению, как уже говорилось, сегодня в массово распространённых языках программирования ничего похожего на уровне
синтаксиса не поддерживается, потому что эти языки не задумывались не только не для параллельной модели, но и не для
поддержки декларативной парадигмы. Поэтому в них поддержка одновременных вычислений если и имеется, то реализована
низкоуровнево (семафоры, мьютексы, async/await), и программисту фактически приходится брать на себя реализацию концепции
dataflow-переменных.

### Дешёвый параллелизм

С помощью нитей можно существенно улучшить структуру программы -- например, сделать её более модульной. В большинстве
крупных программ найдётся много мест, где нити могут успешно применяться, но для этого они должны быть очень дешёвыми и
в плане создания, и в плане потребляемых ресурсов (миллионы одновременных активных нитей на типовом ноутбуке 2021-го
года).

Только помните, что последовательное выполнение всё равно всегда будет более дёшево, нежели выполнение в нитях, но если
параллельная версия улучшает структуру вашего кода, переходите на неё без колебаний.

Ну и конечно, параллельная версия может дать очень большой выигрыш в производительности, если выполняется на
многоядерной системе.

### 6. Сбои

======= 15. Отказ -- это ...

[ 1] ситуация "всё или ничего"

[ ] компромиссная ситуация с обработкой исключений

[ ] естественное свойство декларативной программы

======= 16. Чтобы сохранить декларативность при сбоях, надо ...

[ ] добавить обработчики исключений

[ ] выйти в более общую модель вычислений

[1 ] исключить явный недетерминизм
